{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ada3d7c-9982-40de-97f0-0e2a1240c799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import safetensors\n",
    "\n",
    "from transformers import WhisperTokenizer, WhisperFeatureExtractor\n",
    "from transformers import GenerationConfig\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# import LORA modules\n",
    "from peft import LoraConfig\n",
    "from peft import LoraModel, AdaLoraModel, PeftModel, get_peft_model\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "from pathlib import Path\n",
    "with open(\"../default_paths.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    data_path    = Path(lines[0].strip().split(\"=\")[1])\n",
    "    project_path = Path(lines[1].strip().split(\"=\")[1])\n",
    "    \n",
    "utils_path = project_path / \"utils\"\n",
    "train_path = data_path / \"train\"\n",
    "test_path  = data_path / \"test\"\n",
    "sys.path.insert(0, str(utils_path))\n",
    "\n",
    "from data_utils_lesha import (process_all_files, \n",
    "process_string, \n",
    "save_sentences_to_txt,\n",
    "load_sentences_from_txt,\n",
    "RegularizeConfig,\n",
    "ModelAdaptationConfig,\n",
    "PreprocessConfig,\n",
    "AugmentConfig,\n",
    "configure_input_layers,\n",
    "configure_learnable_layers,\n",
    "WhisperAugmentDataset,\n",
    "DataCollatorSpeechSeq2SeqWithPadding,\n",
    "count_parameters, \n",
    "save_config, \n",
    "load_config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1230098-e5ff-4909-bb78-a93ae19fb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_MODEL_NAME = \"openai/whisper-large-v3\"\n",
    "\n",
    "prev_experiment_path = data_path / \"experiments\" / WHISPER_MODEL_NAME / \"GRADUAL_FULL_dropout\"\n",
    "prev_checkpoint_path = prev_experiment_path / \"checkpoint-6600\"\n",
    "\n",
    "regularize_config = RegularizeConfig().from_json_file(prev_experiment_path / \"regularize_config.json\")\n",
    "adaptation_config = ModelAdaptationConfig().from_json_file(prev_experiment_path / \"adaptation_config.json\")\n",
    "preprocess_config = PreprocessConfig().from_json_file(prev_experiment_path / \"preprocess_config.json\")\n",
    "augment_config    = AugmentConfig().from_json_file(prev_experiment_path / \"augment_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b62ef0-b3b1-4bcd-a88f-0c1f7ac6b5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peft_type': 'LORA',\n",
       " 'auto_mapping': None,\n",
       " 'base_model_name_or_path': None,\n",
       " 'revision': None,\n",
       " 'task_type': 'SEQ_2_SEQ_LM',\n",
       " 'inference_mode': False,\n",
       " 'r': 8,\n",
       " 'target_modules': None,\n",
       " 'lora_alpha': 8,\n",
       " 'lora_dropout': 0.0,\n",
       " 'fan_in_fan_out': False,\n",
       " 'bias': 'none',\n",
       " 'use_rslora': True,\n",
       " 'modules_to_save': None,\n",
       " 'init_lora_weights': True,\n",
       " 'layers_to_transform': None,\n",
       " 'layers_pattern': None,\n",
       " 'rank_pattern': {},\n",
       " 'alpha_pattern': {},\n",
       " 'megatron_config': None,\n",
       " 'megatron_core': 'megatron.core',\n",
       " 'loftq_config': {},\n",
       " 'use_dora': True,\n",
       " 'layer_replication': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_config.lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758f5ef-df3e-416d-9ead-860ff990b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature/label processing engines|\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(WHISPER_MODEL_NAME)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(WHISPER_MODEL_NAME, task=\"transcribe\", language=\"english\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(WHISPER_MODEL_NAME, **regularize_config.to_dict())\n",
    "\n",
    "if \".en\" not in WHISPER_MODEL_NAME:\n",
    "    model.generation_config.language = \"english\"\n",
    "    model.generation_config.task = \"transcribe\"\n",
    "    model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "\n",
    "adaptation_config.adapt_model=\"full\"\n",
    "\n",
    "# adapt model according to adaptation config\n",
    "model = configure_input_layers(model, adaptation_config)\n",
    "model = configure_learnable_layers(model, adaptation_config)\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
