{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "import torch\n",
    "\n",
    "from models.mirasol import Mirasol, MirasolConfig, Franky\n",
    "from models.vq_brain_per_channel import SoundStream, VAEConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.codebook_size 1920\n",
      "self.downsample 8\n",
      "Shape of the rope cache:  torch.Size([512, 8])\n",
      "Full Mirasol model: number of parameters: 15.66M\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 128, 256)\n",
    "\n",
    "\n",
    "vae_config = VAEConfig(C=256, levels=(8, 8, 6, 5))\n",
    "vq_vae = SoundStream(**vae_config.to_dict())\n",
    "\n",
    "config = MirasolConfig(n_electrodes=256, n_registers=8, dim=64, window_size=128)\n",
    "brain_model = Mirasol(config, vq_vae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 128, 256)\n",
    "x[:, 64:] = 0\n",
    "\n",
    "loss, features=brain_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer\n",
    "whisper = {'decoder': model.model.decoder, \n",
    "           'proj_out': model.proj_out, \n",
    "           'tokenizer': tokenizer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Franky: number of parameters: 45.25M\n"
     ]
    }
   ],
   "source": [
    "franky = Franky(brain_model=brain_model, llm_model=whisper) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=384, out_features=51865, bias=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.proj_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = {'one': 2}\n",
    "loss['three'] =  3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 128, 256)\n",
    "\n",
    "txt = tokenizer('I live in Russia', return_tensors='pt')['input_ids']\n",
    "\n",
    "loss2, _ = franky(x, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = [loss, loss2]  # Assuming 'loss' is a dictionary and you have a list of similar dictionaries\n",
    "average_loss = {key: sum(d[key] for d in loss_list) / len(loss_list) for key in loss_list[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'total_loss': tensor(15.8810, grad_fn=<AddBackward0>),\n",
       "  'latent_loss': tensor(0.1429, grad_fn=<RsubBackward1>),\n",
       "  'recon_loss': tensor(7.5791, grad_fn=<NllLossBackward0>),\n",
       "  'txt_loss': tensor(8.1590, grad_fn=<NllLossBackward0>)},\n",
       " {'total_loss': tensor(15.8998, grad_fn=<AddBackward0>),\n",
       "  'latent_loss': tensor(0.1504, grad_fn=<RsubBackward1>),\n",
       "  'recon_loss': tensor(7.5791, grad_fn=<NllLossBackward0>),\n",
       "  'txt_loss': tensor(8.1703, grad_fn=<NllLossBackward0>)}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(15.8904, grad_fn=<DivBackward0>),\n",
       " 'latent_loss': tensor(0.1467, grad_fn=<DivBackward0>),\n",
       " 'recon_loss': tensor(7.5791, grad_fn=<DivBackward0>),\n",
       " 'txt_loss': tensor(8.1646, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'one': 2, 'three': 3}, torch.Size([2, 120, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m is_padded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[0;32m     11\u001b[0m     [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[0;32m     12\u001b[0m     [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[0;32m     13\u001b[0m ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Calculate cosine loss\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_loss\u001b[49m(x, y, is_padded)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m cosine_loss(x[:, :\u001b[38;5;241m2\u001b[39m], y[:, :\u001b[38;5;241m2\u001b[39m], is_padded[:, :\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Test data\n",
    "B, T, D = 2, 5, 3  # Batch size, Time steps, Dimension\n",
    "x = torch.randn(B, T, D)\n",
    "y = torch.randn(B, T, D)\n",
    "\n",
    "# Padding mask (1 where data is valid, 0 where it is padded)\n",
    "is_padded = torch.tensor([\n",
    "    [False, False, True, True, True],\n",
    "    [False, False, True, True, True]\n",
    "], dtype=torch.bool)\n",
    "\n",
    "# Calculate cosine loss\n",
    "loss = cosine_loss(x, y, is_padded)\n",
    "print(\"Cosine Loss:\", loss)\n",
    "\n",
    "loss = cosine_loss(x[:, :2], y[:, :2], is_padded[:, :2])\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.ones(2, 512)\n",
    "\n",
    "torch.repeat_interleave(x, 2, dim=-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
