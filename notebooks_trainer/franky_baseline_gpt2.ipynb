{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import safetensors\n",
    "\n",
    "\n",
    "import einops\n",
    "\n",
    "from models import brainformer\n",
    "from utils.data_utils import BrainDataset, get_tokenizer\n",
    "from utils.train_utils import TrainConfig, run_train_model, count_parameters, simple_train_model\n",
    "\n",
    "\n",
    "from models.brainformer import Encoder, CrossBlock, build_complex_rope_cache, Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from models.gpt2_model import GPT\n",
    "import tiktoken\n",
    "from contextlib import nullcontext\n",
    "from accelerate import notebook_launcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from accelerate.utils import write_basic_config\n",
    "\n",
    "# write_basic_config()  # Write a config file\n",
    "# os._exit(00)  # Restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainEncoder(nn.Module): \n",
    "    config = Config\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.encoder = Encoder(config.encoder)\n",
    "        self.n_output_tokens = config.n_output_tokens\n",
    "\n",
    "        self.learnable_queries = nn.Parameter(torch.zeros(1, config.n_output_tokens, config.dim))\n",
    "        self.perceiver = nn.ModuleDict(dict(\n",
    "                h = nn.ModuleList([CrossBlock(config) for _ in range(config.n_layers)]),\n",
    "                ln_f = nn.LayerNorm(config.dim), \n",
    "                to_words = nn.Linear(config.dim, config.output_dim))\n",
    "        )\n",
    "        \n",
    "        self.register_buffer('cross_attn_mask', None)\n",
    "        self.register_buffer('self_attn_mask', None)\n",
    "\n",
    "        self.precompute_rope_cash = build_complex_rope_cache(dim=config.head_dim,\n",
    "                                                             seq_len=config.n_output_tokens,\n",
    "                                                             theta=config.rope_theta)\n",
    "        # self.cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"Full HandFormer: number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self):\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        return n_params\n",
    "    \n",
    "    @property\n",
    "    def dtype(self) -> torch.dtype:\n",
    "        return next(self.parameters()).dtype\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    @property\n",
    "    def rope_cache(self) -> torch.Tensor:\n",
    "        # Just to use proper device.\n",
    "        if self.precompute_rope_cash.device != self.device:\n",
    "            self.precompute_rope_cash = self.precompute_rope_cash.to(device=self.device)\n",
    "        return self.precompute_rope_cash                \n",
    "    \n",
    "    def forward(self, x, targets=None, date_info=None):\n",
    "        \"\"\"\n",
    "        Get forward pass with loss calculation.\n",
    "        Inputs: \n",
    "        x\n",
    "            shape b t c \n",
    "        targets:\n",
    "            B, C, T\n",
    "        \"\"\"\n",
    "        b, t, c = x.shape\n",
    "\n",
    "        emg_context = self.encoder(x) # b, n_tokens, dim\n",
    "        \n",
    "        input = self.learnable_queries.expand(b, self.n_output_tokens, -1)\n",
    "        \n",
    "        for cross_block in self.perceiver.h:\n",
    "            input = cross_block(input, emg_context, self.self_attn_mask, \n",
    "                                self.cross_attn_mask, sa_rope = self.rope_cache)\n",
    "        \n",
    "        logits = self.perceiver.ln_f(input)\n",
    "        logits = self.perceiver.to_words(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Franky(nn.Module): \n",
    "    \"\"\"This is first model which incorporate brain features into LLM\"\"\"\n",
    "\n",
    "    def __init__(self, brain_model, llm_model, tokenizer=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.brain_model = brain_model\n",
    "        self.llm_model= llm_model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        print(\"Full Franky: number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self):\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        return n_params\n",
    "    \n",
    "    @property\n",
    "    def dtype(self) -> torch.dtype:\n",
    "        return next(self.parameters()).dtype\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x, targets=None, date_info=None):\n",
    "        \"\"\"\n",
    "        Train model.\n",
    "        \"\"\"\n",
    "        features = self.brain_model(x)\n",
    "\n",
    "        new_idx = targets.clone()\n",
    "        new_idx[new_idx == -100] = 50256\n",
    "\n",
    "        loss, logits = self.llm_model.forward(idx=new_idx, prefix=features, targets=targets)\n",
    "\n",
    "        return loss, logits\n",
    "    \n",
    "    def generate(self, x, date_info=None):\n",
    "        \n",
    "        prefix = self.brain_model(x)\n",
    "        \n",
    "        start = '<|endoftext|>'\n",
    "        input_ids = self.tokenizer(start,  return_tensors=\"pt\")['input_ids']\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        \n",
    "        max_new_tokens = 15\n",
    "        temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "        top_k = 20\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y = self.llm_model.generate(x, max_new_tokens, prefix=prefix, temperature=temperature, top_k=top_k)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.0\n",
      "number of parameters: 123.65M\n",
      "Encoder: number of parameters: 4.27M\n",
      "Shape of casual mask:  torch.Size([6144, 6144])\n",
      "Shape of the rope cache:  torch.Size([6144, 16])\n",
      "Full HandFormer: number of parameters: 6.32M\n",
      "Full Franky: number of parameters: 130.76M\n",
      "Initing of the Franky completed\n",
      "Total: 130.76M, Trainable: 6.32M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(130757888, 6318080)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "dtype = torch.float32\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "llm_model = GPT.from_pretrained('gpt2', dict(dropout=0.0))\n",
    "llm_model.eval()\n",
    "\n",
    "for param in llm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "mae_config = brainformer.MAEConfig(window_size=768, patch_size=32)\n",
    "config = brainformer.Config(encoder=mae_config,\n",
    "                            n_output_tokens=32,\n",
    "                            output_dim=llm_model.config.n_embd\n",
    "                            )\n",
    "brain_model = BrainEncoder(config)\n",
    "\n",
    "\n",
    "### Create Franky model\n",
    "model = Franky(brain_model=brain_model, llm_model=llm_model)\n",
    "model.train().to(torch.float32).to(device)\n",
    "\n",
    "print('Initing of the Franky completed')\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0229,  0.0101, -0.0027,  ..., -0.0247,  0.0153,  0.0005],\n",
       "         [ 0.0670, -0.0147, -0.0068,  ..., -0.0044, -0.0117, -0.0123],\n",
       "         [ 0.0188, -0.0051, -0.0379,  ...,  0.0185, -0.0410, -0.0402],\n",
       "         ...,\n",
       "         [ 0.0058,  0.0146, -0.0130,  ...,  0.0190, -0.0231,  0.0086],\n",
       "         [-0.0113,  0.0127,  0.0033,  ...,  0.0024,  0.0237,  0.0085],\n",
       "         [ 0.0214, -0.0044, -0.0212,  ...,  0.0004, -0.0257, -0.0230]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import safetensors\n",
    "\n",
    "weights = Path(\"/drive/logs/kovalev/franky_gpt2_retrain/step_5000_loss_3.1739.safetensors\")\n",
    "\n",
    "safetensors.torch.load_model(model, weights)\n",
    "\n",
    "model.brain_model.state_dict()['learnable_queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runed processing of the  /drive/data/competitionData/train\n",
      "bad_samples [31, 32, 33, 37, 40, 41, 42, 43, 44, 47, 51, 56, 59, 61, 64, 68, 69, 79, 81, 88, 91, 92, 100, 101, 102, 103, 109, 113, 116, 119, 139, 141, 142, 148, 163, 166, 175, 183, 236, 244, 270, 276, 282, 323, 334, 359, 430, 470, 484, 488, 492, 493, 498, 500, 506, 522, 623, 626]\n",
      "Runed processing of the  /drive/data/competitionData/test\n",
      "bad_samples [15, 17, 18, 22]\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"/drive/data/competitionData\")\n",
    "train_dataset = BrainDataset(data_path / 'train', tokenize_function=get_tokenizer(tokenizer))\n",
    "test_dataset = BrainDataset(data_path / 'test', tokenize_function=get_tokenizer(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_scores tensor([-2.0941, -2.0941, -2.0941, -2.0941, -2.0941], device='cuda:0')\n",
      "beam_scores tensor([-6.8935, -6.8935, -7.0580, -7.0580, -7.2391], device='cuda:0')\n",
      "beam_scores tensor([-8.7491, -8.7639, -8.7639, -8.7710, -8.7710], device='cuda:0')\n",
      "beam_scores tensor([ -9.3007,  -9.3007, -10.1013, -10.2525, -10.8006], device='cuda:0')\n",
      "beam_scores tensor([-12.0535, -12.0716, -12.0716, -12.0919, -12.1687], device='cuda:0')\n",
      "beam_scores tensor([-14.0737, -14.2331, -14.6925, -14.7008, -14.7539], device='cuda:0')\n",
      "beam_scores tensor([-14.0741, -15.3781, -15.9495, -15.9592, -17.0501], device='cuda:0')\n",
      "beam_scores tensor([-15.5542, -15.9872, -16.0988, -16.4851, -16.6093], device='cuda:0')\n",
      "beam_scores tensor([-16.3177, -17.0225, -17.2413, -18.4863, -18.6111], device='cuda:0')\n",
      "beam_scores tensor([-17.4008, -17.6843, -18.5156, -18.9971, -19.2119], device='cuda:0')\n",
      "beam_scores tensor([-18.8334, -20.4497, -20.9728, -21.1354, -21.4511], device='cuda:0')\n",
      "beam_scores tensor([-20.6763, -21.3180, -22.1454, -22.4001, -22.5676], device='cuda:0')\n",
      "beam_scores tensor([-20.9728, -21.4087, -22.3771, -22.7878, -23.3997], device='cuda:0')\n",
      "beam_scores tensor([-20.9728, -21.4088, -22.4260, -22.8467, -25.9729], device='cuda:0')\n",
      "beam_scores tensor([-22.4260, -22.8467, -23.1302, -23.5644, -24.0875], device='cuda:0')\n",
      "beam_scores tensor([-24.5776, -25.0133, -26.1061, -26.2730, -26.2892], device='cuda:0')\n",
      "beam_scores tensor([-27.7659, -28.4431, -28.7353, -28.7363, -28.9086], device='cuda:0')\n",
      "beam_scores tensor([-28.9388, -29.3200, -29.4063, -30.3121, -30.4541], device='cuda:0')\n",
      "beam_scores tensor([-30.4182, -31.4077, -31.4206, -31.4636, -31.5243], device='cuda:0')\n",
      "beam_scores tensor([-30.4321, -31.4867, -33.2129, -33.2326, -33.3863], device='cuda:0')\n",
      "beam_scores tensor([-30.4347, -32.5346, -32.5803, -33.5933, -34.3869], device='cuda:0')\n",
      "beam_scores tensor([-30.4347, -33.4155, -34.7234, -34.8744, -35.6619], device='cuda:0')\n",
      "beam_scores tensor([-30.4348, -34.0945, -35.1374, -35.2217, -35.7537], device='cuda:0')\n",
      "beam_scores tensor([-30.4353, -35.1447, -35.8930, -36.6757, -37.2889], device='cuda:0')\n",
      "beam_scores tensor([-30.7400, -31.8754, -35.3285, -36.7080, -37.1900], device='cuda:0')\n",
      "The only way to get rid of them would be to destroy them.\n",
      "beam_scores tensor([-2.0941, -2.0941, -2.0941, -2.0941, -2.0941], device='cuda:0')\n",
      "beam_scores tensor([-7.0580, -7.0580, -7.2391, -7.2391, -7.2694], device='cuda:0')\n",
      "beam_scores tensor([-8.7491, -8.7491, -9.2403, -9.2942, -9.3910], device='cuda:0')\n",
      "beam_scores tensor([-10.2525, -10.4363, -10.8006, -10.8006, -11.0516], device='cuda:0')\n",
      "beam_scores tensor([-12.0919, -12.1308, -12.1710, -12.9616, -12.9616], device='cuda:0')\n",
      "beam_scores tensor([-13.2938, -14.5376, -14.6362, -15.2345, -15.4083], device='cuda:0')\n",
      "beam_scores tensor([-15.4980, -17.0108, -17.2356, -17.3126, -17.9793], device='cuda:0')\n",
      "beam_scores tensor([-17.1906, -17.7214, -18.3863, -19.1798, -19.4310], device='cuda:0')\n",
      "beam_scores tensor([-18.0530, -18.7724, -19.4477, -19.5413, -19.5875], device='cuda:0')\n",
      "beam_scores tensor([-19.2218, -19.8898, -19.9767, -20.8336, -20.8833], device='cuda:0')\n",
      "beam_scores tensor([-20.8102, -21.4176, -21.4374, -21.7104, -22.2565], device='cuda:0')\n",
      "beam_scores tensor([-21.7796, -21.9368, -22.8908, -23.6637, -23.7266], device='cuda:0')\n",
      "beam_scores tensor([-23.4755, -23.6637, -23.8441, -24.0783, -24.7701], device='cuda:0')\n",
      "beam_scores tensor([-23.4755, -26.7966, -26.9509, -26.9593, -27.2977], device='cuda:0')\n",
      "beam_scores tensor([-25.6070, -27.4691, -27.8250, -27.9204, -28.2749], device='cuda:0')\n",
      "beam_scores tensor([-27.8250, -27.9343, -28.4396, -29.2339, -29.5307], device='cuda:0')\n",
      "beam_scores tensor([-27.9344, -30.0160, -30.3005, -30.6821, -30.9809], device='cuda:0')\n",
      "beam_scores tensor([-30.1245, -31.9923, -32.8053, -32.9455, -32.9984], device='cuda:0')\n",
      "beam_scores tensor([-33.5595, -34.1264, -34.3621, -34.8264, -35.2652], device='cuda:0')\n",
      "beam_scores tensor([-35.5285, -36.0121, -36.8021, -36.9667, -36.9930], device='cuda:0')\n",
      "beam_scores tensor([-36.2534, -37.9858, -38.7282, -38.7471, -38.8199], device='cuda:0')\n",
      "beam_scores tensor([-38.7822, -38.9133, -39.0002, -39.2347, -39.6323], device='cuda:0')\n",
      "beam_scores tensor([-39.9094, -39.9981, -40.2042, -40.5069, -41.2098], device='cuda:0')\n",
      "beam_scores tensor([-40.9231, -41.8005, -42.1775, -42.4620, -42.5375], device='cuda:0')\n",
      "beam_scores tensor([-42.6173, -42.7746, -42.7782, -42.8065, -44.0844], device='cuda:0')\n",
      "The next time you see him, you'll know he's a good guy.\n",
      "-------\n",
      "The spray will be used in first division matches next season.\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[2]\n",
    "\n",
    "x = sample[0]\n",
    "x = torch.from_numpy(x[None, ]).to(device)\n",
    "\n",
    "        \n",
    "start = '<|endoftext|>'\n",
    "input_ids = tokenizer(start,  return_tensors=\"pt\")['input_ids']\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "max_new_tokens = 25\n",
    "temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 10\n",
    "\n",
    "for k in range(2):\n",
    "    with torch.no_grad():\n",
    "        prefix = model.brain_model(x)\n",
    "\n",
    "        y = model.llm_model.generate_beam_search(input_ids, max_new_tokens, prefix=prefix, temperature=temperature, beam_width=5)\n",
    "\n",
    "        idxs = (y == 50256).nonzero()\n",
    "\n",
    "        start, end = idxs[0].item() + 1, idxs[1].item()\n",
    "        idxs_clean = y[start:end]\n",
    "        pred = tokenizer.decode(idxs_clean, skip_special_tokens=False)\n",
    "\n",
    "        print(pred)\n",
    "\n",
    "\n",
    "labels = sample[1]\n",
    "labels[labels == -100] = tokenizer.bos_token_id\n",
    "\n",
    "idxs = (labels == 50256).nonzero()[0]\n",
    "start, end = idxs[0] + 1, idxs[1]\n",
    "\n",
    "labels = labels[start: end]\n",
    "\n",
    "gt = tokenizer.decode(labels)\n",
    "\n",
    "print('-------')\n",
    "print(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = '<|endoftext|>i love you so much <|endoftext|>'\n",
    "\n",
    "# input_ids = tokenizer(start,  return_tensors=\"pt\")['input_ids']\n",
    "# input_ids = input_ids.to(device)\n",
    "\n",
    "# brain_activity = torch.randn(1, 768, 256, dtype=torch.float32, device=device)\n",
    "\n",
    "# loss, _ = model.forward(brain_activity, targets=input_ids)\n",
    "\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'frankenstein'\n",
    "\n",
    "train_config = TrainConfig(exp_name='franky_gpt2_retrain',\n",
    "                           mixed_precision=True, \n",
    "                           batch_size=32, \n",
    "                           num_workers=3, \n",
    "                           pin_memory=True, \n",
    "                           eval_interval=500)\n",
    "# peter path\n",
    "# data_path = Path(r'C:\\Users\\peter\\alvi\\brain2text\\competitionData')\n",
    "data_path = Path(\"/drive/data/competitionData\")\n",
    "save_folder = Path(\"/drive/logs/kovalev\")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = BrainDataset(data_path / 'train', tokenize_function=get_tokenizer(tokenizer))\n",
    "test_dataset = BrainDataset(data_path / 'test', tokenize_function=get_tokenizer(tokenizer))\n",
    "\n",
    "\n",
    "args = (model, (train_dataset, test_dataset), train_config, project_name, save_folder)\n",
    "notebook_launcher(run_train_model, args, num_processes=1)\n",
    "\n",
    "# simple_train_model(*args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
