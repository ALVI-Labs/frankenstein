{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\alvi\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "\n",
    "import safetensors\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import notebook_launcher\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from simple_parsing import ArgumentParser\n",
    "import einops\n",
    "\n",
    "from models import brainformer\n",
    "from utils.data_utils import BrainDataset, get_tokenizer\n",
    "from utils.train_utils import TrainConfig, run_train_model, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from models.brainformer import Encoder, CrossBlock, build_complex_rope_cache, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainFormer(nn.Module): \n",
    "    config = Config\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.encoder = Encoder(config.encoder)\n",
    "        self.n_output_tokens = config.n_output_tokens\n",
    "\n",
    "        self.learnable_queries = nn.Parameter(torch.zeros(1, config.n_output_tokens, config.dim))\n",
    "        self.perceiver = nn.ModuleDict(dict(\n",
    "                h = nn.ModuleList([CrossBlock(config) for _ in range(config.n_layers)]),\n",
    "                ln_f = nn.LayerNorm(config.dim), \n",
    "                to_words = nn.Linear(config.dim, config.output_dim))\n",
    "        )\n",
    "        \n",
    "        self.register_buffer('cross_attn_mask', None)\n",
    "        self.register_buffer('self_attn_mask', None)\n",
    "\n",
    "        self.precompute_rope_cash = build_complex_rope_cache(dim=config.head_dim,\n",
    "                                                             seq_len=config.n_output_tokens,\n",
    "                                                             theta=config.rope_theta)\n",
    "        # self.cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"Full HandFormer: number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self):\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        return n_params\n",
    "    \n",
    "    @property\n",
    "    def dtype(self) -> torch.dtype:\n",
    "        return next(self.parameters()).dtype\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    @property\n",
    "    def rope_cache(self) -> torch.Tensor:\n",
    "        # Just to use proper device.\n",
    "        if self.precompute_rope_cash.device != self.device:\n",
    "            self.precompute_rope_cash = self.precompute_rope_cash.to(device=self.device)\n",
    "        return self.precompute_rope_cash                \n",
    "    \n",
    "    def forward(self, x, targets=None, date_info=None):\n",
    "        \"\"\"\n",
    "        Get forward pass with loss calculation.\n",
    "        Inputs: \n",
    "        x\n",
    "            shape b t c \n",
    "        targets:\n",
    "            B, C, T\n",
    "        \"\"\"\n",
    "        b, t, c = x.shape\n",
    "\n",
    "        emg_context = self.encoder(x) # b, n_tokens, dim\n",
    "        \n",
    "        input = self.learnable_queries.expand(b, self.n_output_tokens, -1)\n",
    "        \n",
    "        for cross_block in self.perceiver.h:\n",
    "            input = cross_block(input, emg_context, self.self_attn_mask, \n",
    "                                self.cross_attn_mask, sa_rope = self.rope_cache)\n",
    "        \n",
    "        pred = self.perceiver.ln_f(input)\n",
    "        pred = self.perceiver.to_words(pred)\n",
    "        print(len(pred))\n",
    "        print(i.shape for i in pred)\n",
    "        if targets is None:\n",
    "            return None, pred\n",
    "        # print(pred)\n",
    "        # print(pred[0])\n",
    "        # print(targets)\n",
    "        # print(len(targets))\n",
    "        # 25 токенов\n",
    "        # print(pred[:, :-1].shape)\n",
    "        pred_resh = einops.rearrange(pred[:, :-1], 'b t c -> b c t')\n",
    "        # print(pred_resh.shape)\n",
    "        # target_resh = \n",
    "        # print(targets[:, 1:].shape)\n",
    "        # loss = self.cross_entropy(pred_resh, targets[:, 1:])\n",
    "        loss = F.cross_entropy(pred_resh, targets[:, 1:])\n",
    "        return loss, pred\n",
    "    \n",
    "    @torch.no_grad()    \n",
    "    def inference(self, myo, date_info):\n",
    "        \"\"\"\n",
    "        x (signal) - Time, Channel\n",
    "        OUTPUTS - Time//8, N_BONES\n",
    "        \"\"\"\n",
    "        x = torch.from_numpy(myo)\n",
    "        t, c = x.shape\n",
    "        x = rearrange(x, 't c -> 1 t c', t=t, c=c)\n",
    "        x = x.to(self.device).to(self.dtype)\n",
    "\n",
    "        pred = self.forward(x, targets=None)\n",
    "        pred = pred[0].detach().cpu().numpy()\n",
    "\n",
    "        return pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\alvi\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenize_function = get_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runed processing of the  C:\\Users\\peter\\alvi\\brain2text\\competitionData\\test\n",
      "bad_samples [15, 17, 18, 22]\n",
      "Runed processing of the  C:\\Users\\peter\\alvi\\brain2text\\competitionData\\test\n",
      "bad_samples [15, 17, 18, 22]\n",
      "Encoder: number of parameters: 8.47M\n",
      "Shape of casual mask:  torch.Size([6144, 6144])\n",
      "Shape of the rope cache:  torch.Size([6144, 16])\n",
      "Full HandFormer: number of parameters: 23.23M\n",
      "Total: 23.23M, Trainable: 23.23M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\alvi\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=True)\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeter_chizhov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\peter\\alvi\\brain2text\\frankenstein\\notebooks_trainer\\wandb\\run-20240502_192852-sa8ard4c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/brainformer/runs/sa8ard4c' target=\"_blank\">iconic-serenity-15</a></strong> to <a href='https://wandb.ai/peter_chizhov/brainformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/brainformer' target=\"_blank\">https://wandb.ai/peter_chizhov/brainformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/brainformer/runs/sa8ard4c' target=\"_blank\">https://wandb.ai/peter_chizhov/brainformer/runs/sa8ard4c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for training:  cuda\n",
      "Num devices:  1\n",
      "Completed initialization of scheduler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\alvi\\brain2text\\frankenstein\\models\\brainformer.py:166: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  res = F.scaled_dot_product_attention(q, k, v, attn_mask=attn_mask)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F07B0>\n",
      "tensor([[[ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "         [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "         [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "         ...,\n",
      "         [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "         [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "         [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264]],\n",
      "\n",
      "        [[ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683],\n",
      "         [ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683],\n",
      "         [ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683],\n",
      "         ...,\n",
      "         [ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683],\n",
      "         [ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683],\n",
      "         [ 0.5001, -1.2224, -0.1386,  ..., -0.1943,  0.2050,  0.5683]],\n",
      "\n",
      "        [[ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894],\n",
      "         [ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894],\n",
      "         [ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894],\n",
      "         ...,\n",
      "         [ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894],\n",
      "         [ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894],\n",
      "         [ 0.5394, -1.0612, -0.0072,  ..., -0.0816,  0.1600,  0.4894]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424],\n",
      "         [ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424],\n",
      "         [ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424],\n",
      "         ...,\n",
      "         [ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424],\n",
      "         [ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424],\n",
      "         [ 0.5178, -0.9780,  0.0440,  ..., -0.0184,  0.1448,  0.4424]],\n",
      "\n",
      "        [[ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778],\n",
      "         [ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778],\n",
      "         [ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778],\n",
      "         ...,\n",
      "         [ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778],\n",
      "         [ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778],\n",
      "         [ 0.4479, -1.0571, -0.0311,  ..., -0.0549,  0.1692,  0.4778]],\n",
      "\n",
      "        [[ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096],\n",
      "         [ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096],\n",
      "         [ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096],\n",
      "         ...,\n",
      "         [ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096],\n",
      "         [ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096],\n",
      "         [ 0.4132, -0.9448,  0.0242,  ...,  0.0268,  0.1483,  0.4096]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "        [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "        [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "        ...,\n",
      "        [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "        [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264],\n",
      "        [ 0.4708, -0.9716,  0.0192,  ...,  0.0121,  0.1602,  0.4264]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[50256,    43,  1572,   319,   257,  5318,   329, 24742,   812,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  2227,   284,   467,   284,   326, 13126,  1781,   866,\n",
      "          5366,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1537,   340,   338,  1611,   286,  1327,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,  1595,   470,   423,   281,  1633,  4006,   263,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1549,   588,   284,   766,   883,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 17829,  2173,    13, 50256,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1870,   788,   345, 45799,   262,  9891,   319,  1353,   286,\n",
      "           326,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  3347,   373, 14243, 49293,   287,  3269,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,   338,  1611,   286,   257,   905,  3704,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,   464,  1218,   640,   345,   766,   340,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  4724,  4979,   714,   307,   281, 38650,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,   836,   470,   760,   703,   616,  2988,   750,   340,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F0900>\n",
      "tensor([[[ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "         [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "         [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "         ...,\n",
      "         [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "         [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "         [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961]],\n",
      "\n",
      "        [[ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165],\n",
      "         [ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165],\n",
      "         [ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165],\n",
      "         ...,\n",
      "         [ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165],\n",
      "         [ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165],\n",
      "         [ 0.5653, -1.1401, -0.0479,  ..., -0.1545,  0.1946,  0.5165]],\n",
      "\n",
      "        [[ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675],\n",
      "         [ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675],\n",
      "         [ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675],\n",
      "         ...,\n",
      "         [ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675],\n",
      "         [ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675],\n",
      "         [ 0.4308, -1.0735, -0.0297,  ..., -0.0678,  0.1856,  0.4675]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579],\n",
      "         [ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579],\n",
      "         [ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579],\n",
      "         ...,\n",
      "         [ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579],\n",
      "         [ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579],\n",
      "         [ 0.3362, -1.0411, -0.0344,  ..., -0.0213,  0.1695,  0.4579]],\n",
      "\n",
      "        [[ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679],\n",
      "         [ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679],\n",
      "         [ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679],\n",
      "         ...,\n",
      "         [ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679],\n",
      "         [ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679],\n",
      "         [ 0.5903, -1.0895,  0.0025,  ..., -0.1235,  0.2289,  0.4679]],\n",
      "\n",
      "        [[ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479],\n",
      "         [ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479],\n",
      "         [ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479],\n",
      "         ...,\n",
      "         [ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479],\n",
      "         [ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479],\n",
      "         [ 0.4242, -0.9831,  0.0064,  ...,  0.0105,  0.1466,  0.4479]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "        [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "        [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "        ...,\n",
      "        [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "        [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961],\n",
      "        [ 0.5907, -1.1018, -0.0195,  ..., -0.1280,  0.1892,  0.4961]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[50256,  1537,   345,   836,   470,   760,   326,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1101,  1654,   612,   389,   617,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1975,   340,  3484,   546,  3478,  5054,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1101,   407,   257,  1097, 26419,   393,  1997,   588,\n",
      "           326,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1612,  9965,  1909,   373, 29095,  5054,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  6423,   466,   340,   477,   625,   757,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,   670,   503,   286,   616,  1363,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  5703,  2282,   326,  1598,  5761,   318,   257, 14564,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1537,   340,   468,   257,  2495,  1877,  4065,  2494,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 12441, 21670,   625, 29901,    11,  1239,  1249,  3056,   284,\n",
      "          7523,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2514,  1064,   257,  8598,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1101,  1611,   286,   257,  1097,  6940,  3589,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F07B0>\n",
      "tensor([[[ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5080],\n",
      "         [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "         [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "         ...,\n",
      "         [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "         [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "         [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081]],\n",
      "\n",
      "        [[ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1937,  0.5087],\n",
      "         [ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1937,  0.5087],\n",
      "         [ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1936,  0.5087],\n",
      "         ...,\n",
      "         [ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1936,  0.5087],\n",
      "         [ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1936,  0.5087],\n",
      "         [ 0.5869, -1.0954, -0.0171,  ..., -0.1133,  0.1936,  0.5087]],\n",
      "\n",
      "        [[ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885],\n",
      "         [ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885],\n",
      "         [ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885],\n",
      "         ...,\n",
      "         [ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885],\n",
      "         [ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885],\n",
      "         [ 0.4429, -1.0777, -0.0425,  ..., -0.0518,  0.1715,  0.4885]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891],\n",
      "         [ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891],\n",
      "         [ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891],\n",
      "         ...,\n",
      "         [ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891],\n",
      "         [ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891],\n",
      "         [ 0.5479, -1.0430,  0.0122,  ..., -0.0635,  0.1547,  0.4891]],\n",
      "\n",
      "        [[ 0.5490, -1.0814, -0.0250,  ..., -0.0830,  0.1907,  0.4937],\n",
      "         [ 0.5490, -1.0814, -0.0250,  ..., -0.0831,  0.1907,  0.4938],\n",
      "         [ 0.5490, -1.0814, -0.0250,  ..., -0.0830,  0.1907,  0.4937],\n",
      "         ...,\n",
      "         [ 0.5490, -1.0814, -0.0250,  ..., -0.0831,  0.1907,  0.4938],\n",
      "         [ 0.5490, -1.0814, -0.0250,  ..., -0.0831,  0.1907,  0.4938],\n",
      "         [ 0.5490, -1.0814, -0.0250,  ..., -0.0831,  0.1907,  0.4938]],\n",
      "\n",
      "        [[ 0.4547, -0.9893,  0.0112,  ..., -0.0054,  0.1307,  0.4830],\n",
      "         [ 0.4547, -0.9893,  0.0112,  ..., -0.0055,  0.1307,  0.4830],\n",
      "         [ 0.4546, -0.9893,  0.0112,  ..., -0.0054,  0.1306,  0.4830],\n",
      "         ...,\n",
      "         [ 0.4546, -0.9893,  0.0112,  ..., -0.0054,  0.1307,  0.4830],\n",
      "         [ 0.4546, -0.9893,  0.0112,  ..., -0.0054,  0.1307,  0.4830],\n",
      "         [ 0.4546, -0.9893,  0.0112,  ..., -0.0054,  0.1307,  0.4830]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5080],\n",
      "        [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "        [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "        ...,\n",
      "        [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "        [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081],\n",
      "        [ 0.5578, -1.0992, -0.0546,  ..., -0.1085,  0.1928,  0.5081]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[50256,  3673,  1165,   881, 17797, 10746,    13, 50256,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1101,  9675,   340,   338,  1760,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1544,   550,  7747,   284,   787,    11,   262, 31928,  1297,\n",
      "           683,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  8061,  1234,   606,   287,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  5703,   467,   617,  5372,   329,   262,  1110,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  5703,   257,  1310,  7582,   284,   467,   739,   257,  6050,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,   423,   284,   892,   546,   340,   617,   517,   783,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,   338,   691,   587,   326,   835,   287,   262,   938,\n",
      "          1936,   812,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2990,  1234,   683,   287,   262, 15849,   338,  2607,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2504,   561,   787,   502,  3772,   996,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2504,   314,  1053,  8288,   287,   262,  1613,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,   373,   329,   257,  5123,  4473,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F0900>\n",
      "tensor([[[ 3.5473e-01, -9.4694e-01,  8.1480e-04,  ...,  5.8530e-02,\n",
      "           1.2619e-01,  4.5694e-01],\n",
      "         [ 3.5471e-01, -9.4698e-01,  8.4245e-04,  ...,  5.8480e-02,\n",
      "           1.2619e-01,  4.5699e-01],\n",
      "         [ 3.5465e-01, -9.4694e-01,  8.6643e-04,  ...,  5.8539e-02,\n",
      "           1.2614e-01,  4.5697e-01],\n",
      "         ...,\n",
      "         [ 3.5464e-01, -9.4694e-01,  8.6704e-04,  ...,  5.8530e-02,\n",
      "           1.2615e-01,  4.5699e-01],\n",
      "         [ 3.5464e-01, -9.4693e-01,  8.7067e-04,  ...,  5.8523e-02,\n",
      "           1.2616e-01,  4.5699e-01],\n",
      "         [ 3.5464e-01, -9.4693e-01,  8.7017e-04,  ...,  5.8513e-02,\n",
      "           1.2616e-01,  4.5699e-01]],\n",
      "\n",
      "        [[ 5.0773e-01, -1.2543e+00, -1.4994e-01,  ..., -1.8865e-01,\n",
      "           2.2711e-01,  6.0629e-01],\n",
      "         [ 5.0768e-01, -1.2543e+00, -1.4991e-01,  ..., -1.8873e-01,\n",
      "           2.2709e-01,  6.0635e-01],\n",
      "         [ 5.0764e-01, -1.2543e+00, -1.4990e-01,  ..., -1.8867e-01,\n",
      "           2.2706e-01,  6.0633e-01],\n",
      "         ...,\n",
      "         [ 5.0761e-01, -1.2543e+00, -1.4989e-01,  ..., -1.8867e-01,\n",
      "           2.2706e-01,  6.0636e-01],\n",
      "         [ 5.0761e-01, -1.2543e+00, -1.4989e-01,  ..., -1.8868e-01,\n",
      "           2.2706e-01,  6.0635e-01],\n",
      "         [ 5.0761e-01, -1.2543e+00, -1.4989e-01,  ..., -1.8869e-01,\n",
      "           2.2707e-01,  6.0636e-01]],\n",
      "\n",
      "        [[ 5.0458e-01, -1.0268e+00,  1.0095e-02,  ..., -2.7120e-02,\n",
      "           1.5107e-01,  5.2615e-01],\n",
      "         [ 5.0455e-01, -1.0269e+00,  1.0119e-02,  ..., -2.7190e-02,\n",
      "           1.5107e-01,  5.2621e-01],\n",
      "         [ 5.0450e-01, -1.0268e+00,  1.0141e-02,  ..., -2.7126e-02,\n",
      "           1.5102e-01,  5.2619e-01],\n",
      "         ...,\n",
      "         [ 5.0448e-01, -1.0268e+00,  1.0142e-02,  ..., -2.7136e-02,\n",
      "           1.5103e-01,  5.2621e-01],\n",
      "         [ 5.0448e-01, -1.0268e+00,  1.0146e-02,  ..., -2.7144e-02,\n",
      "           1.5103e-01,  5.2621e-01],\n",
      "         [ 5.0448e-01, -1.0268e+00,  1.0145e-02,  ..., -2.7155e-02,\n",
      "           1.5104e-01,  5.2621e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.6470e-01, -1.0191e+00,  2.4244e-02,  ..., -2.4569e-02,\n",
      "           1.5611e-01,  5.2068e-01],\n",
      "         [ 5.6466e-01, -1.0191e+00,  2.4270e-02,  ..., -2.4649e-02,\n",
      "           1.5611e-01,  5.2073e-01],\n",
      "         [ 5.6462e-01, -1.0191e+00,  2.4291e-02,  ..., -2.4585e-02,\n",
      "           1.5606e-01,  5.2071e-01],\n",
      "         ...,\n",
      "         [ 5.6459e-01, -1.0191e+00,  2.4292e-02,  ..., -2.4595e-02,\n",
      "           1.5607e-01,  5.2074e-01],\n",
      "         [ 5.6459e-01, -1.0191e+00,  2.4296e-02,  ..., -2.4604e-02,\n",
      "           1.5607e-01,  5.2074e-01],\n",
      "         [ 5.6459e-01, -1.0191e+00,  2.4296e-02,  ..., -2.4615e-02,\n",
      "           1.5608e-01,  5.2074e-01]],\n",
      "\n",
      "        [[ 4.9187e-01, -1.1165e+00, -3.5288e-02,  ..., -9.4949e-02,\n",
      "           1.9237e-01,  5.3547e-01],\n",
      "         [ 4.9183e-01, -1.1165e+00, -3.5263e-02,  ..., -9.5021e-02,\n",
      "           1.9236e-01,  5.3553e-01],\n",
      "         [ 4.9178e-01, -1.1165e+00, -3.5241e-02,  ..., -9.4954e-02,\n",
      "           1.9232e-01,  5.3551e-01],\n",
      "         ...,\n",
      "         [ 4.9175e-01, -1.1165e+00, -3.5239e-02,  ..., -9.4963e-02,\n",
      "           1.9233e-01,  5.3553e-01],\n",
      "         [ 4.9176e-01, -1.1165e+00, -3.5235e-02,  ..., -9.4972e-02,\n",
      "           1.9233e-01,  5.3553e-01],\n",
      "         [ 4.9176e-01, -1.1165e+00, -3.5236e-02,  ..., -9.4983e-02,\n",
      "           1.9234e-01,  5.3553e-01]],\n",
      "\n",
      "        [[ 5.8414e-01, -1.0697e+00, -1.4402e-02,  ..., -9.3984e-02,\n",
      "           1.8127e-01,  5.3303e-01],\n",
      "         [ 5.8410e-01, -1.0697e+00, -1.4376e-02,  ..., -9.4072e-02,\n",
      "           1.8127e-01,  5.3308e-01],\n",
      "         [ 5.8406e-01, -1.0697e+00, -1.4358e-02,  ..., -9.4007e-02,\n",
      "           1.8123e-01,  5.3307e-01],\n",
      "         ...,\n",
      "         [ 5.8404e-01, -1.0697e+00, -1.4356e-02,  ..., -9.4016e-02,\n",
      "           1.8123e-01,  5.3309e-01],\n",
      "         [ 5.8404e-01, -1.0697e+00, -1.4351e-02,  ..., -9.4026e-02,\n",
      "           1.8124e-01,  5.3309e-01],\n",
      "         [ 5.8404e-01, -1.0697e+00, -1.4353e-02,  ..., -9.4037e-02,\n",
      "           1.8124e-01,  5.3310e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[ 3.5473e-01, -9.4694e-01,  8.1480e-04,  ...,  5.8530e-02,\n",
      "          1.2619e-01,  4.5694e-01],\n",
      "        [ 3.5471e-01, -9.4698e-01,  8.4245e-04,  ...,  5.8480e-02,\n",
      "          1.2619e-01,  4.5699e-01],\n",
      "        [ 3.5465e-01, -9.4694e-01,  8.6643e-04,  ...,  5.8539e-02,\n",
      "          1.2614e-01,  4.5697e-01],\n",
      "        ...,\n",
      "        [ 3.5464e-01, -9.4694e-01,  8.6704e-04,  ...,  5.8530e-02,\n",
      "          1.2615e-01,  4.5699e-01],\n",
      "        [ 3.5464e-01, -9.4693e-01,  8.7067e-04,  ...,  5.8523e-02,\n",
      "          1.2616e-01,  4.5699e-01],\n",
      "        [ 3.5464e-01, -9.4693e-01,  8.7017e-04,  ...,  5.8513e-02,\n",
      "          1.2616e-01,  4.5699e-01]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[50256, 20570, 13995, 15747,   329,   262,  6387, 30456,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,   836,   470,   760,   611,   345,   423,  1683,  2982,\n",
      "           286,   340,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  8128,   484,  2222,  6541,   284,  1524,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 22210,   257,  1310,  3131,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2061,   338,  1016,   284,  1645,    30, 50256,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  3844,   262,  2911,   373,  3750,    13, 50256,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2484,  2703,  8566,   318,   257,  2968,  2378,   319, 16032,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1135,   651,   503,   319,   262,  1660, 10491,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  3856,  1611,   284,   534,  2187,  2116,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  6104,   287,   616,  1339,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 20644,   290,  2042, 16082,   286,  9230,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,   760,   257,  2576,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F0890>\n",
      "tensor([[[ 4.3485e-01, -1.0966e+00, -4.9212e-02,  ..., -2.4368e-02,\n",
      "           1.7485e-01,  5.8381e-01],\n",
      "         [ 4.3476e-01, -1.0967e+00, -4.9156e-02,  ..., -2.4508e-02,\n",
      "           1.7485e-01,  5.8391e-01],\n",
      "         [ 4.3466e-01, -1.0966e+00, -4.9123e-02,  ..., -2.4371e-02,\n",
      "           1.7475e-01,  5.8386e-01],\n",
      "         ...,\n",
      "         [ 4.3464e-01, -1.0966e+00, -4.9117e-02,  ..., -2.4391e-02,\n",
      "           1.7477e-01,  5.8391e-01],\n",
      "         [ 4.3464e-01, -1.0966e+00, -4.9108e-02,  ..., -2.4405e-02,\n",
      "           1.7478e-01,  5.8391e-01],\n",
      "         [ 4.3464e-01, -1.0966e+00, -4.9107e-02,  ..., -2.4422e-02,\n",
      "           1.7479e-01,  5.8392e-01]],\n",
      "\n",
      "        [[ 4.9768e-01, -1.0218e+00,  1.1450e-02,  ...,  1.7030e-03,\n",
      "           1.7635e-01,  5.3546e-01],\n",
      "         [ 4.9760e-01, -1.0219e+00,  1.1508e-02,  ...,  1.5546e-03,\n",
      "           1.7637e-01,  5.3556e-01],\n",
      "         [ 4.9750e-01, -1.0218e+00,  1.1539e-02,  ...,  1.6873e-03,\n",
      "           1.7625e-01,  5.3552e-01],\n",
      "         ...,\n",
      "         [ 4.9748e-01, -1.0218e+00,  1.1545e-02,  ...,  1.6680e-03,\n",
      "           1.7628e-01,  5.3557e-01],\n",
      "         [ 4.9748e-01, -1.0218e+00,  1.1553e-02,  ...,  1.6534e-03,\n",
      "           1.7629e-01,  5.3557e-01],\n",
      "         [ 4.9748e-01, -1.0218e+00,  1.1554e-02,  ...,  1.6360e-03,\n",
      "           1.7630e-01,  5.3557e-01]],\n",
      "\n",
      "        [[ 3.3925e-01, -1.1255e+00, -5.5638e-02,  ..., -2.8203e-02,\n",
      "           2.0526e-01,  5.7155e-01],\n",
      "         [ 3.3916e-01, -1.1256e+00, -5.5576e-02,  ..., -2.8319e-02,\n",
      "           2.0526e-01,  5.7164e-01],\n",
      "         [ 3.3905e-01, -1.1255e+00, -5.5537e-02,  ..., -2.8188e-02,\n",
      "           2.0515e-01,  5.7159e-01],\n",
      "         ...,\n",
      "         [ 3.3904e-01, -1.1255e+00, -5.5534e-02,  ..., -2.8208e-02,\n",
      "           2.0518e-01,  5.7164e-01],\n",
      "         [ 3.3904e-01, -1.1255e+00, -5.5525e-02,  ..., -2.8221e-02,\n",
      "           2.0518e-01,  5.7164e-01],\n",
      "         [ 3.3904e-01, -1.1255e+00, -5.5523e-02,  ..., -2.8236e-02,\n",
      "           2.0519e-01,  5.7164e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.4472e-01, -1.0598e+00,  2.9721e-04,  ..., -1.9697e-02,\n",
      "           1.5427e-01,  5.7759e-01],\n",
      "         [ 5.4463e-01, -1.0599e+00,  3.5279e-04,  ..., -1.9864e-02,\n",
      "           1.5428e-01,  5.7770e-01],\n",
      "         [ 5.4453e-01, -1.0598e+00,  3.8075e-04,  ..., -1.9726e-02,\n",
      "           1.5418e-01,  5.7766e-01],\n",
      "         ...,\n",
      "         [ 5.4451e-01, -1.0598e+00,  3.8914e-04,  ..., -1.9744e-02,\n",
      "           1.5420e-01,  5.7771e-01],\n",
      "         [ 5.4451e-01, -1.0598e+00,  3.9831e-04,  ..., -1.9759e-02,\n",
      "           1.5421e-01,  5.7771e-01],\n",
      "         [ 5.4451e-01, -1.0598e+00,  3.9850e-04,  ..., -1.9778e-02,\n",
      "           1.5422e-01,  5.7772e-01]],\n",
      "\n",
      "        [[ 2.9019e-01, -1.0184e+00, -2.0476e-02,  ...,  6.1217e-02,\n",
      "           1.5761e-01,  5.3108e-01],\n",
      "         [ 2.9012e-01, -1.0185e+00, -2.0413e-02,  ...,  6.1118e-02,\n",
      "           1.5763e-01,  5.3117e-01],\n",
      "         [ 2.9001e-01, -1.0184e+00, -2.0375e-02,  ...,  6.1243e-02,\n",
      "           1.5751e-01,  5.3112e-01],\n",
      "         ...,\n",
      "         [ 2.9000e-01, -1.0184e+00, -2.0369e-02,  ...,  6.1219e-02,\n",
      "           1.5755e-01,  5.3116e-01],\n",
      "         [ 2.9001e-01, -1.0184e+00, -2.0361e-02,  ...,  6.1208e-02,\n",
      "           1.5756e-01,  5.3116e-01],\n",
      "         [ 2.9001e-01, -1.0184e+00, -2.0360e-02,  ...,  6.1194e-02,\n",
      "           1.5757e-01,  5.3116e-01]],\n",
      "\n",
      "        [[ 3.3112e-01, -1.0629e+00, -3.6887e-02,  ..., -1.0495e-03,\n",
      "           1.8691e-01,  5.2500e-01],\n",
      "         [ 3.3104e-01, -1.0629e+00, -3.6825e-02,  ..., -1.1617e-03,\n",
      "           1.8692e-01,  5.2510e-01],\n",
      "         [ 3.3093e-01, -1.0629e+00, -3.6786e-02,  ..., -1.0301e-03,\n",
      "           1.8680e-01,  5.2504e-01],\n",
      "         ...,\n",
      "         [ 3.3092e-01, -1.0629e+00, -3.6782e-02,  ..., -1.0529e-03,\n",
      "           1.8684e-01,  5.2509e-01],\n",
      "         [ 3.3092e-01, -1.0629e+00, -3.6774e-02,  ..., -1.0642e-03,\n",
      "           1.8684e-01,  5.2509e-01],\n",
      "         [ 3.3092e-01, -1.0629e+00, -3.6772e-02,  ..., -1.0798e-03,\n",
      "           1.8685e-01,  5.2509e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.4348, -1.0966, -0.0492,  ..., -0.0244,  0.1748,  0.5838],\n",
      "        [ 0.4348, -1.0967, -0.0492,  ..., -0.0245,  0.1749,  0.5839],\n",
      "        [ 0.4347, -1.0966, -0.0491,  ..., -0.0244,  0.1747,  0.5839],\n",
      "        ...,\n",
      "        [ 0.4346, -1.0966, -0.0491,  ..., -0.0244,  0.1748,  0.5839],\n",
      "        [ 0.4346, -1.0966, -0.0491,  ..., -0.0244,  0.1748,  0.5839],\n",
      "        [ 0.4346, -1.0966, -0.0491,  ..., -0.0244,  0.1748,  0.5839]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[50256,    40,   466,   407,  1100,  2279,   287,   262,  3348,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,  1107,  5419,   883,   661,    13, 50256,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 12832, 49113, 15409,  3984, 19026,   534, 41220,    13, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    43, 10145,   338, 16569,  2622,  2042, 18051,   284,   307,\n",
      "          3190, 19992,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 31416,   278,  1223,   329,   257,  1787, 46708, 35715,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  6348,   510,   319,   257,  5318,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,    40,  1612,   345,   460,  5160,   257,  1256,   517,  1637,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  3792,   612,   670,   284,  1104,   428,  7664,    30, 50256,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1544,   714,   651,  5938,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,   338,  1611,   286, 37259,  1682,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1532,   314,   836,   470,   423,   257, 35672,   351,   257,\n",
      "          4936,   319,   340,    13, 50256,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1870,   788,   262,  1306,   530,   866,   318,   287,   262,\n",
      "         19586,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*12\n",
      "<generator object BrainFormer.forward.<locals>.<genexpr> at 0x00000284B32F0890>\n",
      "tensor([[[ 0.5599, -1.0875, -0.0141,  ..., -0.0488,  0.1585,  0.6504],\n",
      "         [ 0.5598, -1.0876, -0.0140,  ..., -0.0491,  0.1586,  0.6506],\n",
      "         [ 0.5596, -1.0875, -0.0140,  ..., -0.0489,  0.1584,  0.6505],\n",
      "         ...,\n",
      "         [ 0.5596, -1.0875, -0.0140,  ..., -0.0489,  0.1584,  0.6506],\n",
      "         [ 0.5596, -1.0875, -0.0140,  ..., -0.0490,  0.1585,  0.6506],\n",
      "         [ 0.5596, -1.0875, -0.0140,  ..., -0.0490,  0.1585,  0.6506]],\n",
      "\n",
      "        [[ 0.4697, -1.1211, -0.0664,  ..., -0.0331,  0.1801,  0.6431],\n",
      "         [ 0.4695, -1.1213, -0.0663,  ..., -0.0333,  0.1801,  0.6433],\n",
      "         [ 0.4694, -1.1212, -0.0663,  ..., -0.0332,  0.1800,  0.6432],\n",
      "         ...,\n",
      "         [ 0.4694, -1.1211, -0.0663,  ..., -0.0332,  0.1800,  0.6433],\n",
      "         [ 0.4694, -1.1211, -0.0663,  ..., -0.0332,  0.1800,  0.6433],\n",
      "         [ 0.4694, -1.1211, -0.0663,  ..., -0.0332,  0.1800,  0.6433]],\n",
      "\n",
      "        [[ 0.4171, -1.0086,  0.0158,  ...,  0.0545,  0.1508,  0.6126],\n",
      "         [ 0.4169, -1.0087,  0.0159,  ...,  0.0543,  0.1509,  0.6128],\n",
      "         [ 0.4168, -1.0086,  0.0160,  ...,  0.0544,  0.1507,  0.6127],\n",
      "         ...,\n",
      "         [ 0.4168, -1.0086,  0.0160,  ...,  0.0544,  0.1508,  0.6127],\n",
      "         [ 0.4168, -1.0086,  0.0160,  ...,  0.0544,  0.1508,  0.6127],\n",
      "         [ 0.4168, -1.0086,  0.0160,  ...,  0.0544,  0.1508,  0.6127]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4922, -1.2620, -0.1768,  ..., -0.1445,  0.2067,  0.7068],\n",
      "         [ 0.4920, -1.2621, -0.1767,  ..., -0.1448,  0.2066,  0.7070],\n",
      "         [ 0.4919, -1.2620, -0.1766,  ..., -0.1447,  0.2066,  0.7069],\n",
      "         ...,\n",
      "         [ 0.4918, -1.2620, -0.1766,  ..., -0.1446,  0.2065,  0.7070],\n",
      "         [ 0.4918, -1.2620, -0.1766,  ..., -0.1447,  0.2065,  0.7070],\n",
      "         [ 0.4918, -1.2620, -0.1766,  ..., -0.1447,  0.2066,  0.7070]],\n",
      "\n",
      "        [[ 0.4619, -1.0125,  0.0148,  ...,  0.0412,  0.1488,  0.6143],\n",
      "         [ 0.4617, -1.0126,  0.0149,  ...,  0.0410,  0.1488,  0.6145],\n",
      "         [ 0.4615, -1.0125,  0.0150,  ...,  0.0411,  0.1487,  0.6144],\n",
      "         ...,\n",
      "         [ 0.4615, -1.0125,  0.0150,  ...,  0.0411,  0.1487,  0.6144],\n",
      "         [ 0.4615, -1.0124,  0.0150,  ...,  0.0411,  0.1487,  0.6144],\n",
      "         [ 0.4615, -1.0125,  0.0150,  ...,  0.0411,  0.1488,  0.6145]],\n",
      "\n",
      "        [[ 0.4082, -1.0490, -0.0262,  ...,  0.0223,  0.1539,  0.6061],\n",
      "         [ 0.4080, -1.0491, -0.0261,  ...,  0.0221,  0.1539,  0.6063],\n",
      "         [ 0.4078, -1.0490, -0.0260,  ...,  0.0222,  0.1538,  0.6062],\n",
      "         ...,\n",
      "         [ 0.4078, -1.0490, -0.0260,  ...,  0.0222,  0.1538,  0.6063],\n",
      "         [ 0.4078, -1.0490, -0.0260,  ...,  0.0222,  0.1538,  0.6063],\n",
      "         [ 0.4078, -1.0490, -0.0260,  ...,  0.0222,  0.1538,  0.6063]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.5599, -1.0875, -0.0141,  ..., -0.0488,  0.1585,  0.6504],\n",
      "        [ 0.5598, -1.0876, -0.0140,  ..., -0.0491,  0.1586,  0.6506],\n",
      "        [ 0.5596, -1.0875, -0.0140,  ..., -0.0489,  0.1584,  0.6505],\n",
      "        ...,\n",
      "        [ 0.5596, -1.0875, -0.0140,  ..., -0.0489,  0.1584,  0.6506],\n",
      "        [ 0.5596, -1.0875, -0.0140,  ..., -0.0490,  0.1585,  0.6506],\n",
      "        [ 0.5596, -1.0875, -0.0140,  ..., -0.0490,  0.1585,  0.6506]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[50256,  7571,  1711,  6097,    13, 50256,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  4711,   389,  1760,   351,   257, 10601,  7619,  5049,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2504,   338,  1223,   314,  2051,  2407,   257,  1643,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  5779,   314,  8288,   262, 10037,   444,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1890,   546,   734,  3470,  5054,    13, 50256,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 25302,   534,   898, 13242,    13, 50256,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  5189,  1781,   340,   338,  1103, 11282,    13, 50256,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2396,   345,  1053,  1392,   257,  1256,   286,  4979,  7838,\n",
      "          1103,  1969,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256, 13828,   314,  1807,   373,   257,  1103,  3499,  1808,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  2990,   836,   470,   772,  2198,   616,  1919,  2324,  1271,\n",
      "            13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1639,   836,   470,  5490,   546,   606,  1165,   881,    13,\n",
      "         50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [50256,  1026,   338,  2192,  1016,   284,   307,   257,   845,  1468,\n",
      "           973,   530,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]], device='cuda:0')\n",
      "12\n",
      "torch.Size([12, 24, 50257])\n",
      "torch.Size([12, 50257, 24])\n",
      "torch.Size([12, 24])\n",
      "*"
     ]
    }
   ],
   "source": [
    "project_name = 'brainformer'\n",
    "\n",
    "train_config = TrainConfig(exp_name='brainformer_simple', \n",
    "                           mixed_precision=False, \n",
    "                           batch_size=12)\n",
    "# peter path\n",
    "data_path = Path(r'C:\\Users\\peter\\alvi\\brain2text\\competitionData')\n",
    "# data_path = Path(r\"D:\\Work\\brain-to-text-competition\\data\\competitionData\")\n",
    "\n",
    "\n",
    "train_dataset = BrainDataset(data_path / 'test', tokenize_function=tokenize_function)\n",
    "test_dataset = BrainDataset(data_path / 'test', tokenize_function=tokenize_function)\n",
    "\n",
    "# Init model\n",
    "mae_config = brainformer.MAEConfig(window_size=768)\n",
    "config = brainformer.Config(encoder=mae_config, n_output_tokens=25, output_dim=tokenizer.vocab_size)\n",
    "\n",
    "model = BrainFormer(config)\n",
    "count_parameters(model)\n",
    "\n",
    "args = (model, (train_dataset, test_dataset), train_config, project_name)\n",
    "run_train_model(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.targets_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btch = next(iter(torch.utils.data.DataLoader(train_dataset, batch_size = 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07447474, 0.02272561, 0.03308861, 0.05265393, 0.05520429,\n",
       "       0.03433828, 0.01415561, 0.0619989 , 0.04668124, 0.0270659 ,\n",
       "       0.09160464, 0.03165064, 0.10037031, 0.19572735, 0.04219091,\n",
       "       0.0489976 , 0.04627946, 0.03524334, 0.24202722, 0.06736387,\n",
       "       0.22391742, 0.05963945, 0.03177392, 0.27899384, 0.08874962,\n",
       "       0.06798954, 0.07567943, 0.30999067, 0.03322073, 0.22823244,\n",
       "       0.04652578, 0.21547431, 0.06268316, 0.12725124, 0.04267478,\n",
       "       0.08866527, 0.19836548, 0.04883863, 0.2253061 , 0.08347657,\n",
       "       0.06197602, 0.25438076, 0.06890433, 0.09326004, 0.21797293,\n",
       "       0.0852389 , 0.05124364, 0.21691602, 0.04768499, 0.03850894,\n",
       "       0.07204329, 0.1576474 , 0.05431377, 0.10416052, 0.16920635,\n",
       "       0.2675422 , 0.05770864, 0.05367622, 0.09641687, 0.05243768,\n",
       "       0.03653679, 0.03714343, 0.05742719, 0.04350604, 0.0671173 ,\n",
       "       0.03214645, 0.07087535, 0.22684342, 0.07689945, 0.06472557,\n",
       "       0.06716719, 0.0294333 , 0.07210251, 0.05269102, 0.038257  ,\n",
       "       0.08900432, 0.04974779, 0.06409506, 0.18253565, 0.07194688,\n",
       "       0.06233709, 0.13376942, 0.11003412, 0.0571522 , 0.03053475,\n",
       "       0.08581721, 0.03051962, 0.07950527, 0.06943744, 0.10470577,\n",
       "       0.25903875, 0.03808291, 0.09569942, 0.22044182, 0.05121556,\n",
       "       0.02348013, 0.186883  , 0.08016147, 0.18687123, 0.12431014,\n",
       "       0.20665175, 0.06186704, 0.04010532, 0.09398086, 0.18504682,\n",
       "       0.04650324, 0.21759614, 0.07186284, 0.13184884, 0.22739181,\n",
       "       0.12003245, 0.0346481 , 0.2071392 , 0.02296897, 0.09103768,\n",
       "       0.0705516 , 0.05131785, 0.04987437, 0.05942775, 0.05254608,\n",
       "       0.21428359, 0.0459984 , 0.09356125, 0.26937905, 0.04851935,\n",
       "       0.05098729, 0.05778559, 0.04907216, 0.25245756, 0.05437728,\n",
       "       0.37948242, 0.05652458, 0.06741147, 0.07961085, 0.04419286,\n",
       "       0.16524297, 0.04070349, 0.05436818, 0.06199042, 0.06570158,\n",
       "       0.04365042, 0.04062667, 0.06055845, 0.09691418, 0.10909333,\n",
       "       0.21990582, 0.07083114, 0.08527053, 0.06243739, 0.04729244,\n",
       "       0.04708683, 0.06460834, 0.07235672, 0.04999713, 0.06621487,\n",
       "       0.0261678 , 0.1264914 , 0.03066795, 0.05764417, 0.22956362,\n",
       "       0.10937206, 0.04180057, 0.04603834, 0.1797499 , 0.04348806,\n",
       "       0.06179038, 0.05732443, 0.05113754, 0.25876582, 0.09170475,\n",
       "       0.07210957, 0.02696029, 0.03198915, 0.10221397, 0.10638443,\n",
       "       0.06470143, 0.04263057, 0.07546397, 0.02021986, 0.08735289,\n",
       "       0.08795842, 0.08492365, 0.16999176, 0.0794073 , 0.21760032,\n",
       "       0.09879408, 0.03468367, 0.02002506, 0.09084471, 0.21433058,\n",
       "       0.05640996, 0.02326651, 0.1037456 , 0.05467835, 0.01753035,\n",
       "       0.22236603, 0.04459158, 0.02021462, 0.4901594 , 0.2246153 ,\n",
       "       0.10999606, 0.02898023, 0.02988755, 0.18079048, 0.05537236,\n",
       "       0.05108532, 0.19988433, 0.05573244, 0.12410792, 0.42751652,\n",
       "       0.12120772, 0.07574513, 0.04667635, 0.14078268, 0.05185822,\n",
       "       0.86455834, 0.18812478, 0.08746121, 0.05143508, 0.4649945 ,\n",
       "       0.02002169, 0.06858847, 0.16713253, 0.04689226, 0.04874133,\n",
       "       0.03193526, 0.72145075, 0.05475837, 0.05777717, 0.04065879,\n",
       "       0.03021336, 0.03235302, 0.17823717, 0.03934234, 0.03785583,\n",
       "       0.04069719, 0.04519375, 0.04281059, 0.05734675, 0.02688304,\n",
       "       0.0233793 , 0.03902718, 0.03257561, 0.03067806, 0.5829753 ,\n",
       "       0.07139669, 0.02093522, 0.03110824, 0.06946205, 0.02990814,\n",
       "       0.12191612, 0.05328104, 0.06053632, 0.05905937, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_dataset.__getitem__(0)[0]))\n",
    "train_dataset.__getitem__(0)[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.07447474, 0.02260434, 0.25687808, ..., 0.21139844, 0.04803241,\n",
       "         0.0345922 ],\n",
       "        [0.02272561, 0.03327404, 0.        , ..., 0.18408735, 0.02911673,\n",
       "         0.02720368],\n",
       "        [0.03308861, 0.04182241, 0.24309018, ..., 0.13741817, 0.08524861,\n",
       "         0.01848135],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " [50256,\n",
       "  464,\n",
       "  17818,\n",
       "  23898,\n",
       "  3089,\n",
       "  13,\n",
       "  50256,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100],\n",
       " 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([50256, 50256]),\n",
       " tensor([  464, 14868]),\n",
       " tensor([17818,  8155]),\n",
       " tensor([23898,  1811]),\n",
       " tensor([3089, 4488]),\n",
       " tensor([   13, 24491]),\n",
       " tensor([50256, 33492]),\n",
       " tensor([-100,   13]),\n",
       " tensor([ -100, 50256]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100]),\n",
       " tensor([-100, -100])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(encoder=MAEConfig(window_size=768, n_electrodes=256, patch_size=32, dim=256, n_layers=8, head_dim=32, hidden_dim=1024, n_heads=8, n_kv_heads=8, rope_theta=10000, n_dec_layers=4, decoder_dim=256), n_output_tokens=25, output_dim=50000, dim=256, n_layers=2, head_dim=16, hidden_dim=512, n_heads=4, n_kv_heads=4, rope_theta=10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
